\section{Limitations and Future Work}\label{sec:discussion}

With \FJ we have made a first step to bring together 
the worlds of binary join and \WCOJ algorithms.
There are three obvious limitations that require future work.  Our
current system is main memory only.  If the data were to reside on
disk, then \COLT could be quite inefficient, because it requires
repeated, random accesses to the data.  Another limitation is that the
optimization of a \FJ plan is split into two phases: a
traditional cost-based optimization (currently done by DuckDB),
followed by a heuristic-based optimization of the \FJ plan
(factorization).  This has the advantage of reusing an existing
cost-based optimizer, but the disadvantage is that an integrated
optimizer may be able to find better plans.  Third, our current
optimizer does not make use of existing indices.  It is known that the
optimization problem for join plans becomes harder in the presence of
foreign key indices~\cite{DBLP:journals/pvldb/LeisGMBK015}, and we
expect the same to hold for \FJ plans.  All these limitations require
future work.  As we have designed \FJ to closely capture binary join
while also generalizing it, we hope the solutions to these problems
can also be smoothly transferred from binary join to \FJ.

Finally, we have made several observations during this project, some
of them quite surprising (to us), which we believe deserve a future
study.  We observed that a major bottleneck is the materialization of
intermediate results in bushy plans; an improved materialization
algorithm may speed up \FJ on bushy plans.  One promising idea is to
be more aggressively lazy and keep \COLTs unexpanded during
materialization, which essentially leads to a factorized
representation of the intermediates.  We also observed that, contrary
to common belief, a cyclic query does not necessarily mean \WCOJ
algorithms are faster, and an acyclic query does not mean they are
slow.  A natural question is thus ``when exactly are \WCOJ algorithms
faster than binary join?''  Answering this question will also help us
design a better optimizer for \FJ.  The optimizer can output a plan
closer to \WCOJ when it expects major speedups.  We note that the
query optimizer by~\cite{DBLP:journals/pvldb/FreitagBSKN20} switches
between \GJ and binary join depending on the estimated cardinality.
In contrast, an optimizer for \FJ should smoothly transform a \FJ plan
to fully explore the design space between the two extremes of binary
join and \GJ.  Finally, we realized that, rather surprisingly, \GJ and
traditional joins diverge in their choice of the inner table (called
the cover in our paper): \GJ requires that to be the smallest
(otherwise it is not optimal), while a traditional plan will chose it
to be the largest (to save the cost of computing its hash table).
Future work is required for a better informed decision for the choice
of the inner relation.


%%% Yet, we have been working with the most basic forms 
%%%   of the algorithms, where the data fits into main memory, 
%%%   the algorithms use a single thread. 
%%% Some natural questions to answer next include: 
%%% \begin{itemize}
%%%     \item What data structures can make \FJ efficient on disk?
%%%     \item How can we take advantage of multi-cores to scale up \FJ? And what about distributed \FJ?
%%%     \item How can \FJ make use of indices?
%%% \end{itemize}
%%% These problems have all been well-studied in the context of binary join. 
%%% As we have designed \FJ to closely capture binary join while also generalizing it, 
%%%   we hope the solutions to these problems can also be smoothly transferred 
%%%   from binary join to \FJ.
%%% 
%%% We designed \FJ to take as input an already optimized binary plan, 
%%%   so that it is easy to integrate \FJ into an existing system.
%%% Nevertheless, we expect an optimizer designed for \FJ will find 
%%%   better plans than a traditional optimizer designed for binary join.
%%% Designing optimization algorithms for \FJ can therefore be an 
%%%   important research direction.
%%% 
%%% Throughout the experiments, we have observed one major bottleneck to be the
%%%   materialization of intermediate results. A better materialization algorithm
%%%   than ours may further speed up \FJ on bushy plans. One promising idea is to be
%%%   more aggressively lazy and keep \COLTs unexpanded during materialization, 
%%%   which essentially leads to a factorized representation of the intermediates.
%%% 
%%% Through experiments, we have observed that a cyclic query does not necessarily 
%%% mean \WCOJ algorithms are faster, and an acyclic query does not mean they are slow.
%%% A natural question is thus ``when exactly are \WCOJ algorithms faster than binary join?''
%%% Answering this question will also help us design a better optimizer for \FJ.
%%% The optimizer can output a plan closer to \WCOJ when it expects major speedups. 
%%% We note that the query optimizer by~\cite{DBLP:journals/pvldb/FreitagBSKN20} 
%%%   switches between \GJ and binary join depending on the estimated cardinality.
%%% In contrast, an optimizer for \FJ should smoothly transform a \FJ plan 
%%%   to fully explore the design space between the two extremes of binary join and \GJ.